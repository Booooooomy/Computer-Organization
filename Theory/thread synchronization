**Thread Synchronization(동기화)**

Each thread has: registers, stakcs,..
threads share: program, static data, heap(malloc, new), file descriptions, child process IDs... -> 모든 thread가 공유한다. 책임도 함께 진다.

BIG PROBLEM of using Threads: Threads can stomp on each others' work.

쉬운 예제:
int cnt; // global variable
...
{...cnt++;...} 를 multi thread로 구동했을 때

movl cnt, %eax
addl $1, %eax
movl %eax, cnt

의 과정에서 첫째 줄과 둘째 줄이 서로 다른 thread에 의해 동시 구동되면서 순서를 엉망으로 만들고 잘못된 결과를 초래한다.

사실 global variable을 정의할 때 int volatile cnt; 할 수 있지만 이것도 좋은 방법은 아니다.


그리하여 나온 좋은 방법들:

0. Don't share state among threads.
ex)
time_t t; // 1970-01-01:00:00부터 시작된 카운트. 전역변수.
struct tm *tm;
tm = localtime(&t);
printf("%d-%d-%d", tm->tm_year, tm->tm_mon, tm->tm_day)
라는 녀석을 돌리고 두 개 이상의 thread에게 접근을 가능하게 하면 에러가 생기는 때가 생긴다.
-> 해결법:
{
time_t; // 지역변수.
struct tm m;
tm = localtime_r(&t, &m);
printf(same);
}
이리 하면 우선 전역변수가 없어지니 overlap 할 일이 없고, 각각의 thread는 서로 다른 &m이 있으니 문제 해결.
후자는 reentrant, 전자는 not reentrant. reentrant: recursion,, signal handling, multiple threads...

1. Share the state, but if a thread wants to write, the thread reads to get a lock on the part it's writing.
global lock: one lock for all the shared state(simpler reliable)
small region lock: one lock for each small region(more parallelism)

----------------------------------------------------------------------------------------------------------------------------------

thread synchronization에는 크게 2가지의 동기화가 있다.

-둘 이상의 thread가 동시에 한 메모리에 접근을 하면 문제가 생긴다. 그 원인을 제공하는 코드블럭을 임계영역(critical section)이라고 한다.
임계영역을 동기화 시킴으로서 동시에 여러 개의 thread가 메모리 접근을 못하게 하는 것이 '임계영역에 대한 메모리 접근 동기화'.

-그리고, 우리가 thread 실행을 전반적으로 컨트롤 하는 것은 불가능하다. 그런데 thread A가 B보다 먼저 실행되게 하는 방법은 있다. 이게 '순서 동기화'.

1. 메모리 접근 동기화: 또 다시 2가지로 나뉜다. 유저모드 동기화 vs. 커널모드 동기화. 유저모드는 속도가 빠르지만 커널모드는 기능이 다양하다.
(1) user mode 동기화: Critical section bsaed sync., Interlock function based sync.
(2) kernel mode 동기화: Mutex based sync, Semaphore based sync, Named Mutex...

(1)-1: Critical section based sync:
CRITICAL SECTION 이라는 object 만들고 initialize 해준다. 이 object는 thread가 cirical section에 들어갈 때 꼭 필요한 열쇠다. 
이 열쇠는 한 번에 한 thread에게만 허용된다.
들어갈 때 지참하고(EnterCriticalSection(&CriticalSection)) 나올 때 반납한다(LeaveCriticalSection(&CriticalSection)).
Critical section based sync는 이렇게 이 획득과 반환의 연속이다.

*sidenote: 임계영역을 지정할 때, 만약 임계영역인지 아닌지 헷갈리는 영역이 있으면?
만약 에라 모르겠다 하고 다 임계영역에 때려박으면 프로그램 자체는 stable해진다. 그러나 성능은 말할 수 없을 정도로 엉망이 된다.
그래서 최대한 분석을 빡세게 한 후에 임계영역에서 뺄 수 있는 건 다 빼고 영역을 최소화해야 한다.

예졔:
예를 들어 전역변수 int gTotalcount = 0이 있고 프로그램 내에서 두 개 이상의 함수가 이것을 호출한다고 가정하자. 
그러면 gTotalcount에는 두 개 이상의 scope가 접근을 하며 예상치 못한 에러를 낼 수 있다. 이 때 우리는
'''C++
CRITICAL_SECTION CriticalSection;

foo()
{
EnterCriticalSection(&CriticalSection);
gTotalcount++;
LeaveCriticalSection(&CriticalSection);
}
'''

이런 식으로 접근과 반환 함수를 앞뒤로 껴줌으로서 접근을 제한한다. TOOO EASY.
그런데, 이걸 해 주려면 CRITICAL SECTION object 만들고 initialize 해주고 enter함수 leave함수 만들고 해야할 게 많다. 이때 interlock 함수 등장.

(1)-2: Interlock function based sync.
gaurantees Atomic Access: 한 순간에 하나의 thread에 의해서만 호출이 완료되도록 보장.

예제:
위의 예제와 같은 상황에서:
'''C++
gTotalcount++;
InterlockedIncrement(&gTotalcount); // 다양한 interlock 함수가 있다. 적재적소에 쓸 수 있게 알면 좋다.
'''

(2) Semaphore vs. Mutex
Semaphore기법 중에 binary를 다루는 것이 Mutex 기법이다.
Semaphore는 임계영역을 들어가는 열쇠가 여러 개가 있다. 반면 Mutex는 그 열쇠가 하나 밖에 없다.
다른 말로 하면, Semaphore는 동시에 여러 thread의 접근을 허용하는 반면 mutex는 하나의 접근만을 허용한다.

(2)-1: Mutex based sync:
열쇠가 하나. 매커니즘은 대략 이러하다.
역시나 thread가 critical section에 들어가려면 열쇠가 필요하며 들어가고 나올 때 획득과 반납의 단계를 거친다.
획득 시에는 WaitForSingleObject라는 함수를, 반납시에는 ReleaseMutex라는 함수를 사용한다. 원래 이 열쇠의 주인을 Mutex kernel object이다.
thread가 열쇠를 획득하려면 이 kernel object가 signaled 상태여야 한다. 이때 thread가 획득을 하고 나면 상태는 non-signaled로 바뀐다.
thread가 열쇠를 반납하면 다시 이 상태는 signaled로 바뀌며, 고로 다른 thread가 다시 열쇠를 획득할 수 있는 상태가 된다.

예제:
위의 예제와 같은 상황에서,
'''C++
HANDLE hmutex; 

foo()
{
WaitForSingleObject(hmutex, INFINITE);
gTotalcount++;
ReleaseMutex(hmutex);
}
'''

(2)-2: Semaphore based sync:
열쇠가 여러 개. 매커니즘은 대략 이러하다.
역시나 thread가 임계영역으로 들어갈 때 열쇠를 필요로 하는데, mutex와 다른 점은 mutex kernel object가 카운트의 형식(semaphore count)이라는 것.
thread가 열쇠를 획득할 때 필요한 함수인 WaitForSingleObject가 한 번 불릴 때마다 Semaphore count가 -1 되고, 
반환할 때 필요한 함수인 ReleaseMutex가 한 번 불릴 때마다 semaphore count가 +1이 된다. 
mutex와 같은 방식으로 count가 0이 아닐 때는 signaled 상태이다가, 0이 되는 순간 non-signaled로 바뀐다.

Eggert ver.
'''C++
#include <semaphore.h>
int sem_init(sem_t *s, int flag, unsigned);
int sem_wait(sem_t *); // 위의 wait과 같음, decrement a count.
int sem_post(sem_t *); // 위의 release와 같음, increment a count.
'''

ex)
'''C++
int but[128];
unsigned front, near;
int insert(int p)
{
buf[rear++%128] = p;
}
int remove(void)
{
return buf[front++%128];
}
/*의 꼴이 있을 때, insert와 remove가 두 개의 다른 thread에 의해 동시에 같은 element에 접근하는 등의 문제를 해결하기 위해 semaphore를 쓴다.
두 개의 semaphore - 하나는 위의 문제 해결을 위해, 그리고 하나는 empty queue에서 remove하는 것을 막기 위해.
이 외에도 다양한 이유로 여러 개의 semaphore를 사용할 수 있다*/

sem_t s;
sem_init(&s, null, 128);
sem_t u;
sem_init(&s, null, null);

int but[128];
unsigned front, near;
int insert(int p)
{
sem_post(&s);
buf[rear++%128] = p;
sem_post(&u)
}
int remove(void)
{
sem_wait(&u);
int i = buf[front++%128];
sem_post(&s);
return i;
}
'''

* safe한 code 만들기: 동시에 write하는 녀석이나 특정한 데이터를 대상으로 동시에 read와 write가 여러 군데에서 일어난다면 race condition 확인.

2. 순서 접근 동기화:

순서접근동기화가 필요한 이유: https://www.youtube.com/watch?v=nEBbOigGN1A&index=39&list=PLVsNizTWUw7E2KrfnsyEjTqo-6uKiQoxc
방법: event based synchronization:
평소에 kernel object는 non-signaled 상태. 소비자 thread는 kernel object에 waitforsignalobject 함수를 불러서 상태를 지켜본다.
생산자 thread가 소비자 thread에게 데이터가 준비되었다는 걸 알리기 위해 SetEvent함수를 사용해서 kernel 상태를 signaled로 바꾼다. 
signaled로 바뀌면 소비자는 득달같이 달려들어 데이터를 냠냠쩝쩝한다.

kernel이 signaled냐 non-signaled냐의 상태를 변경해주는 방법에는 manual-reset mode와 auto-reset mode의 2가지가 있다.

manual-reset mode: setevent와 resetevent모두 함수 호출로 kernel 상태 변경.
auto-reset mode: setevent는 여전히 수동, 그러나 waitforsingleobject를 사용해서 resetevent함수 대신 사용.


---------------------------------------------------------------------------------------------------------------------------------

and Eggert talks about multiprocess webservers...





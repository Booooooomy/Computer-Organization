Date: Oct. 30, 2018

참고로 정말 쉬운 건데 학교든 책이든 강의든 어렵게 꼬아서 설명을 해 놔서 이해하기 어려웠다.
정말 쉬운 개념이다.

p106 
**2. 4. 1 비율 이진수(Fractional Binary Numbers)**

기본적으로, Fractional Binary Number의 표시는 다음과 같다.

abcde.fghi(2) 면 이건 a*2^4 + b*2^3 + c*2^2 + d*2^1 + e*2^0 + f*2^(-1) + g*2^(-2) + h*2^(-3) + i*2^(-4) 다.
소수 이진수도 정수 이진수처럼, shift에 의해 2가 곱해지거나 2로 나뉘어지는 효과를 똑같이 가진다.
또, 이진수 표기법으로는 십진수로 표현할 수 있는 모든 수를 완벽히 표현할 수 없다. 예를 들어 1/5 같은 수는 0.2지만 이진법으로는 0.00110011... 이렇게 길게 늘여서 가능한 가까운 수를 찾는 법 뿐이 없다.


**2. 4. 2 IEEE 부동소수점 표시**

부동소수점? 여기서의 부동은 fixed의 '움직이지 않는'이 아니라 'float', 그야말로 '떠다니는'이라는 뜻이다. 소수점이 여기저기 이동할 수 있다는 뜻이다.

우선 표기법은 두 개로 나뉜다. Single precision과 double precision.
Single precision(단정밀도)은 Float datatype(32 bit)을, double precision은 double datatype(64 bit)을 표기한다.


1. Single precision(단정밀도)

기존의 내가 알던 표기법은 큰 수를 표현하기에 비효율적이다. 예를 들어 5 x 2^100 은 101 이후에 100개의 0을 넣어야 한다.
그래서 나온 게 IEEE 부동소수점 표준이다.

- float의 저장

Single precision은 float를 대상으로 한 것이므로 전체가 4byte, 즉 32bit다.
소수는 지수와 가수로 분할되어 아래와 같이 저장된다.

|sign(s)|    Exponent(e) |    Mantissa(f)   |
   31    30            23 22                0
  
어떤 수 x가 있으면 이걸 이진수로 우선 바꾸고, 그걸 다시 규격화된 꼴로 만들어주는데, 크게는 3가지 꼴로 분류할 수 있다.

**bit에 저장된 가수는 bias(float의 경우 127, double의 경우 1203)를 이미 더해준 꼴이며, 우리는 이걸 e라고 부른다.
저장되기 전의 꼴의 가수는 bias가 더해지지 않은 날 것 그대로의 값이며, 우리는 exp라고 부른다.
그러니 float에서 e = exp + 127, double에서는 e = exp + 1203이다.
사실 이걸 확실히 안 해서 다 헷갈리는 거다. 그러니 잘 숙지하도록.**


1. Normalized (exp != 128, exp != -127 즉 e = 255(11111111) 또는 e = 0(00000000) 가 아닌 모든 e)

x = +- 2^exp * (1.f) 꼴. <-- 모두 이미 이진수들이다.

수를 1과 2 사이의 어떤 수 (1.f)와 2의 거듭제곱의 꼴로 만드는 것이다.
이 수를 컴퓨터에 저장할 때에는 32 bit짜리 길다란 막대기의 
sign 자리에 +면 0, -면 1을 넣고, Exponent 자리에 exp + 127 한 값을 넣고, Mantissa 자리에 f(1.부분은 저장 X)를 넣는다.
여기서 127은 bias라고 부르며, 사용하는 이유는 뒤에 설명한다.


2. Denormalized (e = 0 즉 exp = -126 일 때)

**이건 이상하게 e = 0 일 때 exp를 -127이 아니라 -126으로 가진다.
무슨 1-127을 해줘서 -126 이라는데, 걍 외워야겠다.**

x = +- 2^exp * (0.f) 꼴. <-- 모두 이미 이진수들이다.
ex) x = s|00000000|whatever f

수를 0과 1 사이의 어떤 수 (0.f)와 2의 거듭제곱의 꼴로 만든다. 저장은 위와 똑같은 방식으로 한다.


3. Infinity, Zero, NaN

Zero: exp = -127(e = 0), f = 0 일 때 우리는 이걸 0으로 정의한다 (s는 뭐든지 상관없이 0이다)
Infinity: exp = 128(e = 255), f = 0 일 때 우리는 이걸 무한으로 정의한다.
NaN: exp = 128(e = 255), f != 0 일 때 이 수는 'undefined' 수가 되며, 우리는 컴퓨터가 무슨 행위를 할 지 예상할 수 없다.
      - NaN과 닿은 것들은 모두 NaN으로 변한다. 그리고 만약 NaN이 bool을 만나면 무조건 그 값은 0, 즉 False가 된다. 그래서 NaN == NaN 의 결과는 0.



- 표현 가능 범위

Mantissa는 정밀도를 결정하고, Exponent는 좀 더 큰 scope로서 표현 가능한 수의 범위를 결정한다.
범위 안에 있다고 실제로 모두 표현 가능한 것은 아니다. 왜냐면 아까처럼 0.2와 같은 숫자는 이진법으로 표현하기가 불가능하기 때문이다.
그러나 표현 가능 범위를 따질 때 이걸 심각하게 고려하지는 않는다.


- Biased exponent

bias를 쓰는 이유는 수를 bit에 저장할 때 signed가 아닌 unsigned로 저장하고 싶기 때문.


-------------------------------------------------------------------------------------------------------------------

**BFPN arithmetic**

위에서 실수의 저장방법을 보았다면, 어떻게 연산하는지 보자.
참고로 정수는 논리, 산술 연산이 다 있지만 실수는 논리연산이 없고 산술 연산만 있다.

- 덧셈/뺄셈
지수를 먼저 맞추고 가수끼리 덧/뺄셈을 해준 뒤 나온 결과를 normalization.

- 곱셈/나눗셈
가수끼리 연산하고 지수끼리 연산. 그리고 normalization.

- 산술연산에서 발생 가능한 문제들
1. exponent overflow: +inf, -inf 로 set.
2. exponent underflow: 0으로 set.
3. mantissa overflow: normalization
4. mantissa underflow: 내림.

- double, float, int casting

얘네끼리 casting 해줄 때 두 가지 - 정확도, overflow 고려해야 한다.

우선 int -> double, float -> double 은 아무 문제 없다.
int -> float 은 근사가 될 수 있다. 범위는 문제 없다.
float -> int, double -> float, double -> int 는 모두 근사가 될 수 있고, 범위도 문제 있어서 overflow의 가능성이 있다.

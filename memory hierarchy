**Memory Hierarchy**

memory의 계층 구조는 다음과 같다: registers -> L1 -> L2 -> L3 (모두 SRAM) -> DRAM -> Disk -> Github.

ex)
교수의 컴퓨터 기종: AMD Phenom II X4 910e (2010)
이 컴퓨터의 스펙은 이렇다: 512 KiB L2 cahce 4개, 6 MiB L3 cache, 8 GiB DRAM, 4TN disk, and some github, 64 KiB +64 KiB (Instruction+Data) L1 cache
(Ki, Mi, Gi, Ti, Pi, Ei)

이 경우 L1은 reg의 32배, L2는 L1의 16배, L3은 L2의 3배, DRAM은 L3의 1000배가 넘고, Disk는 DRAM의 500배다.
저장하는 사이즈가 커지면 CPU로부터의 거리가 멀다는 것이고 동시에 속도와 퍼포먼스도 형편없어진다.
잘 보면 L(cache)끼리는 크기 차이가 상대적으로 작은데 DRAM부터는 확 커진다. 왜? 전혀 다른 technology를 사용하기 때문이다.


RAM: Random Access Memory(all accesses are equally fast: which is not entirely true)

1. SRAM(static): faster, expensive, requires more power, more area
                  보통은 cache가 SRAM이라고 한다.
                  6 transistor circuit for 1 bit, and bistable(volatile = if power off, everything vanishes).
2. DRAM(dynamic): slower, cheap, less power, less area
                  no transistor. works by a charge on a capacitor. this slowly leaks - power가 계속 있어도 결국 서서히 잊어버린다.
                  so constantly refreshed by the controller. loading in and out data frequently.
                  Many DRAM chips in sequence in a memory module
 -> momory modlue: [highest order bit of each byte] [] [] [] [] [] [] [lowest order bit of each byte]


NVRAM: nonvolatile RAM: survives power outages. ex) disk, electornic memories...

1. PROM: programmable read-only memory.
2. EPROM: electronically reprogrammable " (reprogrammable via separate device).
3. EEPROM: electronically reprogrammable, and no need to use a seperate device.

- Flash라고 부르기도 한다. 느리지만 DISK 대신 사용하기도 한다.



Disks: usually stacked on top of each other.

|-----그____   이런 식으로 여러 개의 actuator의 header가 platter(디스크 판때기)를 청진하듯 대고 있으면 디스크가 빠르게 돌면서 정보를 전달 혹은 공수.
|-----그____   capacity: total surfaces of platters * area * track density(줄끼리의 간격) * recording density(줄 내부의 bit 간격)
|-----그____   seek latency: header을 해당 track으로 옯기는 데 걸리는 시간, rotational latency: header을 옮긴 후 해당 부분이 올 때까지 기다리는 시간.




자, 그럼 이제 순리를 거슬러 보자.
지금까지는 데이터를 많이 저장할 수 있으면 상대적으로 접근하기가 어렵고 또 느리고, 빨리 접근할 수 있는 부분은 데이터를 조금밖에 저장 못하곤 했었는데, 우리는 빠르지만 많은 데이터를 저장하는 녀석을 만들고 싶은 욕망에 빠졌다.
그 욕망은, 우리로 하여금 cache를 만들게끔 이끌어냈다.

Caching: cache를 사용하는 행위가 caching이다. 그럼 cache가 뭔가?
level k는 level k+1의 cache다.
예를 들어 우리가 자주 보는 책은 책장에서 뽑아서 더 가까운 책상 위에 두는 것과 같다. CPU가 많이 쓸 것 같은 data를 cache에 저장해 두는 것이다. 참고로 cache는 SRAM이다.

Cache hit: cache에 CPU가 필요한 정보가 있는 경우 <=> Cache miss: 없는 경우

따로 'Cache'라는 소프트웨어나 하드웨어가 있는 것이 아니다. L1이 캐시 역할을 하려면 L2가 backing storage가 되는 것이고, L2가 캐시라면 L3가 그 역을 하는 것이다.
backing storage의 정보를 cache에 집어넣는 방법에는 2가지가 있다.

a) direct-mapped cache: backing storage의 정보의 주소의 하위 몇 바이트만 따서 그걸로 해당하는 cache에 넣어주기.
                        이건 아주 빠르고 쉽긴 하지만 별로 안 좋은 방법이다. 왜냐하면 하위 4자리 딴다고 했을 때 10101110과 11111110이 모두 하위 네 자리 1110을 가졌기에 서로 구별할 수 없기 때문이다.
b) (2-way, 4-way)set-associative mapping: cache를 아주 작은 여러 개의 cache set(cache line, set)으로 나눠서 거따가 정보를 집어넣기. 앞서 다룬 direct map에서의 문제점은 같은 하위 주소를 가진 놈은 하나밖에 못 넣는다는 것이었는데, set- associative는 그걸 n개로 나눈다.
                                          이를테면 2-way는 1110의 장소를 11100과 11101의 두 개로 나눠서 같은 하위 bit를 가진 2개의 정보를 받고, 4-way는 111000 111001 111010 111011의 4개로 나눠 4개의 정보를 받는다.

L1 cache는 보통 2-4 cycle, L2 cache는 10, L3 cache는 30-40 cycle 걸림.

Locality: 
Spatial locality: 메인메모리에서 CPU가 요청한 주소지점의 데이터에 인접한 주소의 데이터들이 앞으로 참조될 가능성이 높음을 뜻함.
Temporal locality: 한 번 참조되었던 데이터는 후에 다시 참조될 가능성이 높음을 뜻함.






Cache miss하는 2가지 큰 이유와 해결법:
1. 프로그램이 너무 많은 data를 필요로 해서 그 개수가 cache의 용량을 초과하는 경우 -> array의 크기를 cache에 맞춰라?
2. Hash collision: CPU에서 cache를 뒤질 때 주로 Hash를 쓰는데, 이 때 같은 hash value에 겹치는 녀석이 여러가지가 있어서 cache의 해당 정보를 못 찾는 경우이다.

Cache와 storage의 데이터 변경 시 Write hit policy: 
1. Write-through: 즉시 쓰기. cache에 write함과 동시에 storage에도 write하는 방식 (cache와 storage 값이 항상 동일, 그러나 너무 느림)
2. Write-back: 나중에 쓰기. cache의 변경을 하고도 바로 storage에 가는 게 아니라, cache의 다른 어떤 녀석이 변경될 때 storage에 기록하는 방식. 이건 storage에 가는 횟수를 줄이기에 상대적으로 빠르지만, cache의 변화가 실시간으로 storage에 업뎃이 안 된다는 단점 또한 있다.


